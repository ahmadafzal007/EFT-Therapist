{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EFT Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.memory import BaseMemory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from typing import Any, List, Optional, Dict\n",
    "import logging\n",
    "from langchain.chains import LLMChain\n",
    "from typing import Dict, Any, Optional, Callable\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.memory import ConversationBufferWindowMemory  # Import for reinitializing memory\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Gemini LLM using Google GenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeminiLLM(LLM):\n",
    "    \"\"\"\n",
    "    Custom LLM that uses the Gemini API via the Google GenAI client.\n",
    "    GEMINI_API_KEY is loaded from the .env file.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Configure the Gemini API\n",
    "        genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "        \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"gemini\"\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        model = genai.GenerativeModel('gemini-1.5-pro')\n",
    "        \n",
    "        # Handle general queries differently\n",
    "        if self._is_general_query(prompt):\n",
    "            return self._handle_general_query(prompt)\n",
    "            \n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "\n",
    "    def _is_general_query(self, prompt: str) -> bool:\n",
    "        \"\"\"Check if the prompt is a general greeting or simple question.\"\"\"\n",
    "        general_queries = [\n",
    "            \"hello\", \"hi\", \"hey\", \"greetings\", \"how are you\", \n",
    "            \"how's it going\", \"what's up\", \"good morning\", \n",
    "            \"good afternoon\", \"good evening\", \"help\", \"what is eft\"\n",
    "        ]\n",
    "        \n",
    "        prompt_lower = prompt.lower().strip()\n",
    "        \n",
    "        for query in general_queries:\n",
    "            if prompt_lower.startswith(query) or prompt_lower == query:\n",
    "                return True\n",
    "        return False\n",
    "        \n",
    "    def _handle_general_query(self, prompt: str) -> str:\n",
    "        \"\"\"Provide a concise, friendly response to general queries.\"\"\"\n",
    "        prompt_lower = prompt.lower().strip()\n",
    "        \n",
    "        if any(greeting in prompt_lower for greeting in [\"hello\", \"hi\", \"hey\", \"greetings\"]):\n",
    "            return \"Hello! I'm your EFT Therapy Assistant. How are you feeling today? I'm here to help guide you through emotional freedom techniques.\"\n",
    "        elif \"how are you\" in prompt_lower or \"how's it going\" in prompt_lower or \"what's up\" in prompt_lower:\n",
    "            return \"I'm here and ready to support you with EFT techniques. How are you feeling today? Is there something specific you'd like to work on?\"\n",
    "        elif any(greeting in prompt_lower for greeting in [\"good morning\", \"good afternoon\", \"good evening\"]):\n",
    "            return \"Thank you, and the same to you! I'm your EFT Therapy Assistant. How can I support your emotional wellbeing today?\"\n",
    "        elif \"help\" in prompt_lower:\n",
    "            return (\"I'm here to help you with Emotional Freedom Techniques (EFT). \"\n",
    "                    \"You can share how you're feeling, describe emotional challenges, or ask for guidance on specific issues. \"\n",
    "                    \"I'll provide personalized tapping sequences to help you process emotions and find relief.\")\n",
    "        elif \"what is eft\" in prompt_lower:\n",
    "            return (\"EFT (Emotional Freedom Techniques) is a powerful self-help method that combines elements of cognitive therapy with acupressure. \"\n",
    "                    \"By tapping on specific meridian points while focusing on an issue, EFT helps release emotional blockages and reduce stress. \"\n",
    "                    \"It's often called 'psychological acupressure' and can help with anxiety, stress, trauma, and other emotional challenges.\")\n",
    "        else:\n",
    "            return \"I'm your EFT Therapy Assistant. How can I support you today?\"\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"model\": \"gemini-pro\",\n",
    "            \"temperature\": 0.7,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the EFT Therapy System using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EFTTherapySystem:\n",
    "    def __init__(self):\n",
    "        logger.debug(\"Initializing EFTTherapySystem.\")\n",
    "        self.llm = GeminiLLM()\n",
    "        self.memory = ConversationBufferWindowMemory(\n",
    "            memory_key=\"chat_history\",\n",
    "            return_messages=True,\n",
    "            k=10  # Keep last 10 messages\n",
    "        )\n",
    "        \n",
    "        self.decomposition_prompt = PromptTemplate(\n",
    "            input_variables=[\"input\", \"chat_history\"],\n",
    "            template=\"\"\"You are a Task Decomposition Specialist for EFT (Emotional Freedom Techniques) therapy.\n",
    "            \n",
    "Your role is to break down complex EFT queries into clear, actionable subtasks.\n",
    "\n",
    "Given the following query and conversation history, break down the query into specific therapeutic needs:\n",
    "\n",
    "Query: {input}\n",
    "\n",
    "Conversation History: {chat_history}\n",
    "\n",
    "List each subtask on a new line, focusing on key therapeutic needs. Be sensitive to emotional cues and underlying issues:\n",
    "\"\"\"\n",
    "        )\n",
    "        self.decomposition_chain = LLMChain(llm=self.llm, prompt=self.decomposition_prompt)\n",
    "        \n",
    "        self.expert_prompt = PromptTemplate(\n",
    "            input_variables=[\"input\", \"subtasks\", \"chat_history\"],\n",
    "            template=\"\"\"You are an EFT Therapy Expert with years of experience in Emotional Freedom Techniques.\n",
    "            \n",
    "You help patients address emotional challenges through tapping techniques, combining clinical expertise with warm empathy.\n",
    "\n",
    "Based on the following subtasks identified for this query, provide expert EFT guidance addressing each component:\n",
    "\n",
    "Original Query: {input}\n",
    "\n",
    "Subtasks:\n",
    "{subtasks}\n",
    "\n",
    "Conversation History: {chat_history}\n",
    "\n",
    "For each subtask, provide:\n",
    "1. A brief validation of the feeling or concern\n",
    "2. Clear tapping instructions with specific phrases to say during tapping\n",
    "3. A comforting rationale for why this approach helps\n",
    "\n",
    "Use a warm, conversational tone as if you're speaking directly to the person. Include gentle encouragement and normalize their experience:\n",
    "\"\"\"\n",
    "        )\n",
    "        self.expert_chain = LLMChain(llm=self.llm, prompt=self.expert_prompt)\n",
    "        \n",
    "        self.coordinator_prompt = PromptTemplate(\n",
    "            input_variables=[\"input\", \"expert_guidance\", \"chat_history\"],\n",
    "            template=\"\"\"You are an EFT Session Coordinator skilled at creating conversational, empathetic therapeutic responses.\n",
    "            \n",
    "Your task is to create a cohesive, empathetic response that feels like a real therapist is talking directly to the client.\n",
    "\n",
    "Original Query: {input}\n",
    "\n",
    "Expert Guidance:\n",
    "{expert_guidance}\n",
    "\n",
    "Conversation History: {chat_history}\n",
    "\n",
    "Create a response that:\n",
    "1. Opens with a warm, personalized greeting that acknowledges their feelings\n",
    "2. Presents the EFT guidance in a conversational, easy-to-follow format\n",
    "3. Uses supportive language and occasional questions to engage them\n",
    "4. Closes with encouragement and an invitation to share how they feel after trying the techniques\n",
    "\n",
    "The response should feel like a caring conversation, not a clinical instruction manual. Use natural language with some variation in sentence structure, occasional gentle questions, and empathetic observations:\n",
    "\"\"\"\n",
    "        )\n",
    "        self.coordinator_chain = LLMChain(llm=self.llm, prompt=self.coordinator_prompt)\n",
    "    \n",
    "    def process_query(self, user_query: str, progress_callback: Optional[Callable] = None) -> Dict[str, str]:\n",
    "        memory_vars = self.memory.load_memory_variables({})\n",
    "        chat_history = memory_vars.get(\"chat_history\", \"\")\n",
    "        \n",
    "        if self.llm._is_general_query(user_query):\n",
    "            response = self.llm._handle_general_query(user_query)\n",
    "            self.memory.save_context({\"input\": user_query}, {\"output\": response})\n",
    "            return {\n",
    "                \"subtasks\": \"General query\",\n",
    "                \"expert_guidance\": \"Direct response\",\n",
    "                \"final_response\": response\n",
    "            }\n",
    "        \n",
    "        if progress_callback:\n",
    "            progress_callback(\"Listening to your concerns...\", 0.2)\n",
    "        \n",
    "        decomposition_result = self.decomposition_chain.run({\n",
    "            \"input\": user_query,\n",
    "            \"chat_history\": chat_history\n",
    "        })\n",
    "        \n",
    "        if progress_callback:\n",
    "            progress_callback(\"Preparing personalized EFT guidance...\", 0.5)\n",
    "        \n",
    "        expert_result = self.expert_chain.run({\n",
    "            \"input\": user_query,\n",
    "            \"subtasks\": decomposition_result,\n",
    "            \"chat_history\": chat_history\n",
    "        })\n",
    "        \n",
    "        if progress_callback:\n",
    "            progress_callback(\"Crafting a supportive response for you...\", 0.8)\n",
    "        \n",
    "        final_result = self.coordinator_chain.run({\n",
    "            \"input\": user_query,\n",
    "            \"expert_guidance\": expert_result,\n",
    "            \"chat_history\": chat_history\n",
    "        })\n",
    "        \n",
    "        if progress_callback:\n",
    "            progress_callback(\"Ready with your guidance\", 1.0)\n",
    "        \n",
    "        self.memory.save_context({\"input\": user_query}, {\"output\": final_result})\n",
    "        \n",
    "        return {\n",
    "            \"subtasks\": decomposition_result,\n",
    "            \"expert_guidance\": expert_result,\n",
    "            \"final_response\": final_result\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Chatbot Class with Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25768\\3661093643.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  self.memory = ConversationBufferWindowMemory(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25768\\3661093643.py:26: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  self.decomposition_chain = LLMChain(llm=self.llm, prompt=self.decomposition_prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the EFT Therapy System. Type 'exit' to quit.\n",
      "\n",
      "Assistant:\n",
      " {'subtasks': 'General query', 'expert_guidance': 'Direct response', 'final_response': \"Hello! I'm your EFT Therapy Assistant. How are you feeling today? I'm here to help guide you through emotional freedom techniques.\"} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25768\\3661093643.py:93: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  decomposition_result = self.decomposition_chain.run({\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    eft_system = EFTTherapySystem()\n",
    "\n",
    "    print(\"Welcome to the EFT Therapy System. Type 'exit' to quit.\\n\")\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            break\n",
    "        try:\n",
    "            answer = eft_system.process_query(user_input)\n",
    "            print(\"Assistant:\\n\", answer, \"\\n\")\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "            import traceback\n",
    "\n",
    "            traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
